# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y1ROUV8E2vkof8fx7ZlpZF6eM-gGNY9d
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# importing modules for CNN
from keras.models import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import SGD
import keras

# for image accesing and processing
from matplotlib.image import imread
import os
import cv2
from PIL import Image,ImageEnhance

"""Accessing the data"""

train_dir='/content/drive/MyDrive/Tire Textures/training_data'
test_dir='/content/drive/MyDrive/Tire Textures/testing_data'

train_folders=os.listdir(train_dir)
test_folders=os.listdir(test_dir)
print(train_folders)
print(test_folders)

"""Number of images in both training data folders and testing folders"""

def count_images(data_folder):
  for folder in train_folders:
    print(folder,len(os.listdir(os.path.join(train_dir,folder))))

print("Number of images in testing data")
count_images(train_folders)
print("Number of images in testing data")
count_images(test_folders)

"""Look into the data"""

for folder in train_folders:
    filenames=os.listdir(os.path.join(train_dir,folder))
    print('Number of samples in {} class is {}\n'.format(folder, len(filenames)))
    fig, ax = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))
    for i in range(16):
        plt.subplot(4, 4, i+1)
        filepath = os.path.join(train_dir, folder, filenames[i])
        image = imread(filepath)
        plt.imshow(image)
        plt.xticks([0, image.shape[0]])
        plt.yticks([0, image.shape[1]])
    plt.suptitle(folder.capitalize())
    plt.show()
    print('\n')

"""Get variations in size"""

def img_files(get_path):
  img=[]
  label=[]
  for folder in os.listdir(get_path):
    for file in os.listdir(os.path.join(get_path,folder)):
      img.append(os.path.join(get_path,folder,file))
      label.append(folder)
  return img,label

train_files,train_labels=img_files(train_dir)
test_files,test_labels=img_files(test_dir)
sizes=[]
labels=[]
for folder in os.listdir(train_dir):
  for file in os.listdir(os.path.join(train_dir,folder)):
    img=Image.open(os.path.join(train_dir,folder,file))
    sizes.append(img.size)
    labels.append(folder)
sizes_df=pd.DataFrame(sizes,columns=['width','height'])
sizes_df['label']=labels
print(sizes_df.head())
print(sizes_df.tail())

"""Plotting the distribution of sizes"""

plt.figure(figsize=(10,10))
sns.histplot(data=sizes_df,x=sizes_df['width'],hue=sizes_df['label'])
plt.xlabel(' Image Size')
plt.ylabel('Distribution')
plt.title('Image Size Distribution')
plt.show()

plt.pie(sizes_df['label'].value_counts(),autopct='%1.1f%%',labels=sizes_df['label'].value_counts().index)
plt.title('Distribution of images based on classes')

sns.pairplot(sizes_df,hue='label')

sns.barplot(x=sizes_df['label'],y=sizes_df['width'],hue=sizes_df['label'],color=sns.color_palette()[0],palette='Set2')
plt.xlabel('Image Class')
plt.ylabel('Distribution')
plt.title('Image Size Distribution')

"""to understand small image size and large image sizes"""

# plotting an image with size< 300
for folder in os.listdir(train_dir):
    if folder=="cracked":
      cracked_small_300=np.where((sizes_df['width']<300) & (sizes_df['label']==folder))
      cracked_large_2500=np.where((sizes_df['width']>2500) & (sizes_df['label']==folder))
      img_small=Image.open(train_files[cracked_small_300[0][0]])
      img_large=Image.open(train_files[cracked_large_2500[0][0]])
      plt.subplot(2,1,1)
      plt.imshow(img_small)
      plt.xticks([0,img_small.size[0]])
      plt.yticks([0,img_small.size[1]])
      plt.title("Cracked images with small size")
      plt.show()
      plt.subplot(1,2,2)
      plt.imshow(img_large)
      plt.xticks([0,img_large.size[0]])
      plt.yticks([0,img_large.size[1]])
      plt.title("Cracked images with large size")
      plt.tight_layout()
      plt.show()

"""Check quality of issues in the training data"""

!pip install cleanvision

from cleanvision.imagelab import Imagelab
for folder in train_folders:
  image_lab=Imagelab(os.path.join(train_dir,folder))
  image_lab.find_issues()
  image_lab.report()
  # image_lab.quality_check()
  # image_lab.quality_check_summary()
  # image_lab.quality_check_summary_plot()

"""Data Augmentation"""

datagen=ImageDataGenerator(
    rotation_range=360,
    fill_mode='nearest',
    shear_range=0.2,
    zoom_range=0.4,
    horizontal_flip=True,
    vertical_flip=True,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.5,1],
    validation_split=0.2
)

train_data_gen=datagen.flow_from_directory(
    train_dir,
    target_size=(842,842),
    color_mode='grayscale',
    classes = {"normal": 0, "cracked": 1},
    batch_size=32,
    class_mode='binary',
    subset='training'
)
val_data_gen=datagen.flow_from_directory(
    train_dir,
    target_size=(842,842),
    color_mode='grayscale',
    classes = {"normal": 0, "cracked": 1},
    batch_size=32,
    class_mode='binary',
    subset='validation')

test_data_gen=datagen.flow_from_directory(
    test_dir,
    color_mode='grayscale',
    classes = {"normal": 0, "cracked": 1},
    target_size=(842,842),
    batch_size=32,
    class_mode='binary'
)

class_dict=train_data_gen.class_indices
mapping_class={v:k for k,v in class_dict.items()}
mapping_class
def visualizeImageBatch(dataset, title):
    images, labels = next(iter(dataset))
    images = images.reshape(32, *(842,842))
    fig, axes = plt.subplots(8, 8, figsize=(16,16))

    for ax, img, label in zip(axes.flat, images, labels):
        ax.imshow(img, cmap = "gray")
        ax.axis("off")
        ax.set_title(mapping_class[label], size = 20)

    plt.tight_layout()
    fig.suptitle(title, size = 30, y = 1.05, fontweight = "bold")
    plt.show()

    return images

train_images = visualizeImageBatch(train_data_gen,
                                   "FIRST BATCH OF THE TRAINING IMAGES\n(WITH DATA AUGMENTATION)")

val_images = visualizeImageBatch(val_data_gen,
                                   "FIRST BATCH OF THE VALIDATION IMAGES\n(WITH DATA AUGMENTATION)")

test_images = visualizeImageBatch(test_data_gen,
                                   "FIRST BATCH OF THE TESTING IMAGES\n(WITH DATA AUGMENTATION)")

from fastcore.all import *
from fastai.vision.all import *

def sharpness(item,value):
    if(isinstance(item, PILImage)):
        tmpEnhancer = ImageEnhance.Sharpness(item)
        return tmpEnhancer.enhance(value)
    return item

def sharpnessL(value):
    return lambda x : sharpness(x,value)

train_val_data = ImageDataLoaders.from_folder(train_dir,valid_pct=0.2, seed=42,
    item_tfms=[Resize(224, method='squish'),sharpnessL(4)],
    batch_tfms=aug_transforms(size=224, min_scale=0.90),
    bs=32)

train_val_data.show_batch(max_n=6)

train_val_data.train

if len(train_val_data.valid) == 0:
    raise ValueError("dlsSharpness.valid_ds is empty. Please assign a valid dataset.")

!pip install timm

import timm

learner = vision_learner(train_val_data, 'resnet26d', metrics=[accuracy,error_rate])
learner.fine_tune(20)

learner.show_results(max_n=15)

learner.lr_find()

print(learner)



interp=ClassificationInterpretation.from_learner(learner)
interp.plot_confusion_matrix()

interp.plot_top_losses(6,figsize=(10,10))

interp.print_classification_report()

interp.most_confused()

learner.save('/content/drive/MyDrive/Tire Textures')

data = {
    'epoch': list(range(20)),
    'train_loss': [0.239496, 0.194688, 0.156436, 0.142155, 0.137269, 0.131148, 0.109835, 0.099376, 0.098090, 0.100482,
                   0.095386, 0.089624, 0.076935, 0.075484, 0.064168, 0.053535, 0.053154, 0.045230, 0.039444, 0.032893],
    'valid_loss': [0.522606, 0.609158, 0.593918, 0.488203, 0.676418, 0.548820, 0.469309, 0.523436, 0.612900, 0.596528,
                   0.637717, 0.527607, 0.500692, 0.502825, 0.527544, 0.539243, 0.541809, 0.565711, 0.554011, 0.548720],
    'accuracy': [0.885714, 0.857143, 0.885714, 0.892857, 0.878571, 0.878571, 0.892857, 0.900000, 0.885714, 0.892857,
                 0.885714, 0.892857, 0.900000, 0.900000, 0.900000, 0.892857, 0.892857, 0.892857, 0.892857, 0.892857],
    'error_rate': [0.114286, 0.142857, 0.114286, 0.107143, 0.121429, 0.121429, 0.107143, 0.100000, 0.114286, 0.107143,
                   0.114286, 0.107143, 0.100000, 0.100000, 0.100000, 0.107143, 0.107143, 0.107143, 0.107143, 0.107143]}

df = pd.DataFrame(data)

import matplotlib.pyplot as plt

# Plotting training loss
plt.plot(df['epoch'], df['train_loss'], label='Training Loss')
plt.plot(df['epoch'], df['valid_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plotting accuracy
plt.plot(df['epoch'], df['accuracy'], label='Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()
plt.show()

resBasic = []
tst_files = get_image_files(test_dir)

for file in tst_files:
    a = file
    a = str(a).split('/')
    resBasic.append([a[-1], a[-2], learner.predict(file, with_input=True)[1]])
    'ok'

resBasic_df=pd.DataFrame(resBasic,columns=['File','Class','Prediction'])
resBasic_df.head()

rigth = 0
wrong = 1
for x in resBasic:
    if(x[1] == x[2]):
        rigth=rigth+1
    else:
        wrong=wrong+1

precision = rigth/(rigth+wrong)
print('Rigth:', rigth)
print('Wrong:', wrong)
print('Precision:', precision)

from sklearn.metrics import confusion_matrix
cfn_mtrx=confusion_matrix(resBasic_df['Class'],resBasic_df['Prediction'])
sns.heatmap(cfn_mtrx,annot=True,cmap='Blues',fmt='d',cbar=False,xticklabels=['cracked','normal'],yticklabels=['cracked','normal'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()